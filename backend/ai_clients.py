# ai_clients.py (Final version with command-nightly model)

import io
import os
import json
import requests
import tempfile
from typing import List
from dotenv import load_dotenv

load_dotenv()

# --- AI Model Imports ---
import cohere
from firebase_admin import storage

# --- Initialize Clients ---
# Cohere (for text generation)
co = cohere.Client(os.environ.get("COHERE_API_KEY"))

# ---------------- Product Ideas ---------------- #
def generate_product_ideas(skills: List[str], materials: List[str]) -> List[str]:
    """Generate product ideas from skills and materials using Cohere."""
    prompt = (
        f"Generate 5 simple, practical, culturally appropriate product ideas "
        f"for someone with skills: {', '.join(skills)} "
        f"and materials: {', '.join(materials)}. "
        f"Return the result as a JSON array of strings."
    )
    try:
        response = co.chat(
            model='command-nightly',  # <<< FINAL MODEL NAME UPDATE
            message=prompt
        )
        text = response.text.strip()
        
        text = text.replace("```json", "").replace("```", "").strip()
        try:
            return json.loads(text)
        except json.JSONDecodeError:
            # Fallback parsing for plain list format
            return [line.strip("-â€¢ ") for line in text.split("\n") if line.strip()]
    except Exception as e:
        print("Error generating ideas:", e)
        # Provide a fallback response so the app doesn't crash
        return ["Handmade bag", "Decorative lamp", "Woven mat"]


# ---------------- Government Schemes ---------------- #
def get_government_schemes(profile: dict):
    """Fetch relevant schemes based on artisan profile using Cohere."""
    prompt = f"""
    You are an assistant that suggests relevant Indian Government Schemes.
    Based on the following user profile, suggest 5 schemes.

    User Profile:
    - Location: {profile.get("location")}
    - Skills: {", ".join(profile.get("skills", []))}
    - Bio: {profile.get("bio")}

    Task:
    Return your response as a valid JSON array of objects. Each object must have two keys: "name" (the scheme's official name) and "desc" (a brief, one-sentence description).
    Do not include any text or formatting outside of the JSON array.
    
    Example format:
    [
      {{"name": "Scheme Name 1", "desc": "Description of scheme 1."}},
      {{"name": "Scheme Name 2", "desc": "Description of scheme 2."}}
    ]
    """
    try:
        response = co.chat(
            model='command-nightly',  # <<< FINAL MODEL NAME UPDATE
            message=prompt
        )
        text = response.text.strip()

        # Clean up and parse the JSON response
        text = text.replace("```json", "").replace("```", "").strip()
        schemes = json.loads(text)
        return schemes
    except Exception as e:
        print(f"Error generating/decoding schemes from AI: {e}")
        # Fallback for any error
        return [{"name": "Pradhan Mantri Mudra Yojana (PMMY)", "desc": "Provides loans up to 10 lakh to non-corporate, non-farm small/micro enterprises."}]


# ---------------- Speech to Text ---------------- #
def speech_to_text(audio_bytes: bytes) -> str:
    return "This function will be implemented in the future."


# ---------------- Text to Speech ---------------- #
def text_to_speech(text: str, language_code: str = "en-IN") -> str:
    return "This function will be implemented in the future."

# ---------------- Image Generation ---------------- #
# This function remains unchanged as it uses Hugging Face
HF_TOKEN = os.environ.get("HF_TOKEN", "")

def generate_mockup_image(description: str) -> dict:
    try:
        url = "https://router.huggingface.co/hf-inference/models/black-forest-labs/FLUX.1-dev"
        headers = {"Authorization": f"Bearer {HF_TOKEN}"}
        payload = {"inputs": description}
        resp = requests.post(url, headers=headers, json=payload, timeout=60)
        resp.raise_for_status()
        image_bytes = resp.content
        return {
            "image_bytes": image_bytes,
            "mime": "image/png",
            "notes": "Generated by Hugging Face (Stable Diffusion)"
        }
    except Exception as e:
        print(f"Hugging Face error: {e}")
        return {"image_bytes": b"", "mime": "image/png", "notes": f"ERROR: {str(e)}"}


# ---------------- Firebase Storage Upload ---------------- #
def upload_image_to_storage(path: str, data: bytes, content_type: str) -> str:
    # This function remains unchanged
    bucket = storage.bucket()
    blob = bucket.blob(path)
    blob.upload_from_string(data, content_type=content_type)
    blob.make_public()
    return blob.public_url


# ---------------- Embeddings ---------------- #
def embed_text(text: str) -> str:
    return "This function will be implemented in the future."

